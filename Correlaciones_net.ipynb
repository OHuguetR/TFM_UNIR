{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "abd0a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 0) Imports necesarios ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9030a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1) Leer y preparar los datos para el modelo, variable X y variable Y ===\n",
    "\n",
    "df = pd.read_csv(\"ventas_mensuales - TODAS-Mod.csv\", sep=\";\", decimal=\".\", encoding=\"utf-8\") #Leer el archicvo CSV con separador ; y codificación Latin1\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%d/%m/%Y\") #Convertir la columna 'date' a formato datetime\n",
    "ventas_col = \"value\" # Nombre de la columna de ventas\n",
    "familia_col = \"Familia\" # Nombre de la columna de familia\n",
    "y = df.set_index(\"date\").sort_index()[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e857b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2) Crear tabla pivot por familias y calcular crecimiento porcentual ===\n",
    "\n",
    "# Crear tabla pivot con fechas como índice, familias como columnas y suma de ventas como valores\n",
    "df_pivot = df.pivot_table(\n",
    "    index=\"date\",\n",
    "    columns=familia_col,\n",
    "    values=ventas_col,\n",
    "    aggfunc=\"sum\"\n",
    ").sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7af58fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3) Condicional para modelar según si se tiene encuenta el COVID o no ===\n",
    "\n",
    "covid = 0 # 0 = Sin datos de la etapa COVID; 1 = Con datos de la etapa COVID\n",
    "COVID_START = \"2020-03-01\" # Fecha considerada de inicio del periodo COVID\n",
    "COVID_END   = \"2021-12-01\" # Fecha considerada de fin del periodo COVID\n",
    "\n",
    "# Condicional para enmascarar los datos del periodo COVID si covid == 0\n",
    "if covid == 0:\n",
    "    y_masked = y.copy()\n",
    "    y_masked.loc[COVID_START:COVID_END] = np.nan\n",
    "    \n",
    "    df_pivot_masked = df_pivot.copy()\n",
    "    df_pivot_masked.loc[COVID_START:COVID_END, :] = np.nan\n",
    "\n",
    "else:  \n",
    "    y_masked = y.copy()\n",
    "    df_pivot_masked = df_pivot.copy()\n",
    "\n",
    "pivot_used = df_pivot_masked if covid == 0 else df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7b43d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3b) Transformación logarítmica de los datos para modelar según si se tiene en cuenta el COVID o no ===\n",
    "\n",
    "y_masked_log   = np.log1p(y_masked) # Transformación logarítmica de la variable Y\n",
    "pivot_used_log = np.log1p(pivot_used) # Transformación logarítmica de las variables X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b4cb9b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Familia</th>\n",
       "      <th>Mesa</th>\n",
       "      <th>Mini Tumbona</th>\n",
       "      <th>Parasol</th>\n",
       "      <th>Sillas</th>\n",
       "      <th>Tumbona</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Familia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mesa</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.074710</td>\n",
       "      <td>0.234815</td>\n",
       "      <td>-0.135872</td>\n",
       "      <td>-0.260789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mini Tumbona</th>\n",
       "      <td>-0.074710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034962</td>\n",
       "      <td>0.275357</td>\n",
       "      <td>0.037756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parasol</th>\n",
       "      <td>0.234815</td>\n",
       "      <td>-0.034962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016748</td>\n",
       "      <td>-0.033249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sillas</th>\n",
       "      <td>-0.135872</td>\n",
       "      <td>0.275357</td>\n",
       "      <td>-0.016748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.245350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tumbona</th>\n",
       "      <td>-0.260789</td>\n",
       "      <td>0.037756</td>\n",
       "      <td>-0.033249</td>\n",
       "      <td>0.245350</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Familia           Mesa  Mini Tumbona   Parasol    Sillas   Tumbona\n",
       "Familia                                                           \n",
       "Mesa          1.000000     -0.074710  0.234815 -0.135872 -0.260789\n",
       "Mini Tumbona -0.074710      1.000000 -0.034962  0.275357  0.037756\n",
       "Parasol       0.234815     -0.034962  1.000000 -0.016748 -0.033249\n",
       "Sillas       -0.135872      0.275357 -0.016748  1.000000  0.245350\n",
       "Tumbona      -0.260789      0.037756 -0.033249  0.245350  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 4) MATRIZ DE CORRELACIÓN ENTRE FAMILIAS (CRECIMIENTOS) ===\n",
    "\n",
    "crec_familias = df_pivot.pct_change() # Calcular crecimiento porcentual mensual entre familias\n",
    "corr_familias = crec_familias.corr() # Calcular matriz de correlación entre familias basándose en los crecimientos porcentuales\n",
    "display(corr_familias) # Mostrar la matriz de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "00d1a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROBABILIDAD: P(fam2 sube | fam1 sube)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mesa</th>\n",
       "      <th>Mini Tumbona</th>\n",
       "      <th>Parasol</th>\n",
       "      <th>Sillas</th>\n",
       "      <th>Tumbona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mesa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.45614</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mini Tumbona</th>\n",
       "      <td>0.448276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.603448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parasol</th>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.57971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sillas</th>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tumbona</th>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.59322</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Mesa  Mini Tumbona   Parasol    Sillas   Tumbona\n",
       "Mesa               NaN       0.45614  0.631579  0.596491  0.473684\n",
       "Mini Tumbona  0.448276           NaN  0.689655  0.517241  0.603448\n",
       "Parasol       0.521739       0.57971       NaN  0.579710  0.594203\n",
       "Sillas        0.531250       0.46875  0.625000       NaN  0.593750\n",
       "Tumbona       0.457627       0.59322  0.694915  0.644068       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 5) PROBABILIDAD P(fam2 sube | fam1 sube) ===\n",
    "\n",
    "n_familias = len(df_pivot.columns) # Número de familias en el DataFrame pivot\n",
    "\n",
    "# Condicional para calcular la probabilidad solo si hay al menos 2 familias\n",
    "if n_familias >= 2:\n",
    "    prob_subida_dict = {}\n",
    "    \n",
    "    # Calcular P(fam2 sube | fam1 sube) para cada par de familias\n",
    "    for fam1 in df_pivot.columns:\n",
    "        for fam2 in df_pivot.columns:\n",
    "            if fam1 == fam2:\n",
    "                continue\n",
    "\n",
    "            A = crec_familias[fam1] > 0   # fam1 sube\n",
    "            B = crec_familias[fam2] > 0   # fam2 sube\n",
    "\n",
    "            # Calcular la probabilidad condicional P(fam2 sube | fam1 sube)\n",
    "            if A.sum() > 0:\n",
    "                prob = (A & B).sum() / A.sum()\n",
    "                prob_subida_dict[(fam1, fam2)] = prob\n",
    "\n",
    "    prob_subida = pd.Series(prob_subida_dict).unstack() # Convertir el diccionario a DataFrame para mejor visualización\n",
    "    print(\"\\nPROBABILIDAD: P(fam2 sube | fam1 sube)\")\n",
    "    display(prob_subida)\n",
    "else:\n",
    "    print(\"\\nSólo hay una familia, no se puede calcular P(fam2 sube | fam1 sube).\")\n",
    "    prob_subida = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "03eebb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relaciones fuertes (P>= 0.60):\n",
      "Mesa → ['Parasol']\n",
      "Mini Tumbona → ['Parasol', 'Tumbona']\n",
      "Sillas → ['Parasol']\n",
      "Tumbona → ['Parasol', 'Sillas']\n"
     ]
    }
   ],
   "source": [
    "# === 6) SELECCIÓN DE FAMILIAS RELACIONADAS SEGÚN PROB_SUBIDA ===\n",
    "\n",
    "umbral_prob = 0.6 # Umbral de probabilidad para considerar una relación fuerte\n",
    "relaciones_fuertes = {}   # Diccionario para almacenar relaciones fuertes\n",
    "\n",
    "# Extraer relaciones fuertes basadas en el umbral de probabilidad\n",
    "if not prob_subida.empty:\n",
    "    # Iterar sobre cada familia y sus probabilidades condicionales\n",
    "    for fam1 in prob_subida.index:\n",
    "        rels = prob_subida.loc[fam1].dropna()\n",
    "        fuertes = rels[rels >= umbral_prob].index.tolist()\n",
    "        # Si hay relaciones fuertes, añadirlas al diccionario\n",
    "        if fuertes:\n",
    "            relaciones_fuertes[fam1] = fuertes\n",
    "\n",
    "# Mostrar las relaciones fuertes encontradas\n",
    "print(f\"\\nRelaciones fuertes (P>= {umbral_prob:.2f}):\")\n",
    "for k, v in relaciones_fuertes.items():\n",
    "    print(f\"{k} → {v}\")\n",
    "else:\n",
    "    if prob_subida.empty:\n",
    "        print(\"\\nNo hay matriz de prob_subida (sólo una familia o datos insuficientes).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3bc4b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7) Preparar las variables exógenas ===\n",
    "\n",
    "cols_exog = [\"Sol\",\"Precipitación\",\"Agosto\",\"Tendencia\",\"Festivos\",\"Temperatura\",\"ICC\"]  # Con todas las variables exógenas disponibles.\n",
    "cols_exog = [c for c in cols_exog if c in df.columns] # Filtrar solo las columnas que existen en el DataFrame\n",
    "\n",
    "for c in cols_exog: # Transformar y preparar las variables exógenas\n",
    "    df[c] = df[c].astype(str) # Convertir a string para reemplazar comas\n",
    "    df[c] = df[c].str.replace(\",\", \".\", regex=False) # Reemplazar comas por puntos decimales\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\") # Convertir a numérico, forzando errores a NaN\n",
    "\n",
    "# Verificar tipos de datos de las columnas exógenas\n",
    "# print(\"Columnas del df:\")\n",
    "# print(df.columns)\n",
    "# df[cols_exog].dtypes\n",
    "\n",
    "# Preparar la variable X con las columnas exógenas\n",
    "X = (\n",
    "    df[[\"date\"] + cols_exog]\n",
    "    .drop_duplicates(subset=\"date\")\n",
    "    .set_index(\"date\")\n",
    "    .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fabce965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Familias relacionadas con Tumbona (P>= 0.60): ['Parasol', 'Sillas']\n",
      "                   ds         y   Sol  Precipitación  Agosto  Tendencia  \\\n",
      "date                                                                      \n",
      "2015-02-01 2015-02-01  8.696343  3.74           0.36       0         22   \n",
      "2015-03-01 2015-03-01  9.490167  5.74           1.91       0         51   \n",
      "2015-04-01 2015-04-01  9.641538  8.04           0.37       0         58   \n",
      "2015-05-01 2015-05-01  9.445966  9.14           0.93       0         59   \n",
      "2015-06-01 2015-06-01  9.035392  9.77           0.36       0         53   \n",
      "2015-07-01 2015-07-01  9.445412  8.38           0.45       0         47   \n",
      "2015-08-01 2015-08-01  8.001690  8.78           1.36       1         34   \n",
      "2015-09-01 2015-09-01  8.114025  5.96           1.37       0         20   \n",
      "2015-10-01 2015-10-01  8.471568  3.86           2.41       0         14   \n",
      "2015-11-01 2015-11-01  8.554682  3.58           0.60       0         11   \n",
      "\n",
      "            Festivos  Temperatura    ICC  Parasol_lag1  Sillas_lag1  \n",
      "date                                                                 \n",
      "2015-02-01         0         9.60   99.0      4.248495     6.208590  \n",
      "2015-03-01         0        12.90  100.4      0.693147     7.275172  \n",
      "2015-04-01         1        15.20  101.8      4.867534     6.966967  \n",
      "2015-05-01         1        19.38  103.1      5.834811     7.642044  \n",
      "2015-06-01         0        23.47  101.4      6.068426     6.966024  \n",
      "2015-07-01         0        27.05  105.6      0.881285     7.231287  \n",
      "2015-08-01         0        25.28  105.9      6.408529     7.490529  \n",
      "2015-09-01         0        21.48  106.1      5.129899     5.241747  \n",
      "2015-10-01         1        18.08   99.8      3.784190     6.167516  \n",
      "2015-11-01         0        14.58  104.6      0.693147     5.003946  \n"
     ]
    }
   ],
   "source": [
    "# === 8) Preparar DataFrame final para Prophet con variable Y y variables exógenas + familias relacionadas ===\n",
    "\n",
    "FAM_OBJ = \"Tumbona\" # Familia objetivo\n",
    "\n",
    "# Comprobar que la familia objetivo existe en el DataFrame pivot\n",
    "if FAM_OBJ not in pivot_used_log.columns:\n",
    "    raise ValueError(f\"La familia objetivo {FAM_OBJ} no existe en tabla_familias.columns\")\n",
    "\n",
    "familias_rel = relaciones_fuertes.get(FAM_OBJ, []) # Familias relacionadas según prob_subida\n",
    "print(f\"Familias relacionadas con {FAM_OBJ} (P>= {umbral_prob:.2f}):\", familias_rel) # Familias relacionadas según prob_subida\n",
    "\n",
    "LAG_FAM = 1 # Número de periodos de lag para las familias relacionadas\n",
    "\n",
    "\n",
    "\n",
    "df_prophet = pd.DataFrame(index=pivot_used_log.index) # DataFrame final para Prophet\n",
    "df_prophet[\"ds\"] = df_prophet.index # Fecha como índice\n",
    "df_prophet[\"y\"]  = pivot_used_log[FAM_OBJ]  # Variable Y para la familia objetivo\n",
    "\n",
    "\n",
    "df_prophet = df_prophet.join(X, how=\"left\") # añadir variables exógenas\n",
    "\n",
    "# Añadir variables de familias relacionadas con lag\n",
    "for fam_rel in familias_rel:\n",
    "    col_name = f\"{fam_rel}_lag{LAG_FAM}\"\n",
    "    df_prophet[col_name] = pivot_used_log[fam_rel].shift(LAG_FAM)\n",
    "\n",
    "df_prophet = df_prophet.dropna() # Eliminar filas con valores NaN\n",
    "df_prophet = df_prophet.sort_values(\"ds\") # Ordenar por fecha\n",
    "\n",
    "# # Guardar el DataFrame final para Prophet en un archivo Excel\n",
    "# df_prophet.to_excel(\"df_prophet_final.xlsx\")\n",
    "print(df_prophet.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5547d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 9) Definición de funciones para el cálculo de métricas de evaluación ===\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "def rmse(y_verd, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_verd)**2))\n",
    "\n",
    "# Mean Absolute Error (MAE) \n",
    "def mae(y_verd, y_pred):\n",
    "    return np.mean(np.abs(y_pred - y_verd))\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE) con denominador seguro\n",
    "def mape_safe(y_verd, y_pred, eps=1.0):\n",
    "    denom = np.maximum(np.abs(y_verd), eps)\n",
    "    return np.mean(np.abs(y_pred - y_verd) / denom) * 100.0\n",
    "\n",
    "# Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "def smape(y_verd, y_pred, eps=1e-8):\n",
    "    denom = np.abs(y_verd) + np.abs(y_pred)\n",
    "    denom = np.where(denom < eps, eps, denom)\n",
    "    return np.mean(2.0 * np.abs(y_pred - y_verd) / denom) * 100.0\n",
    "\n",
    "# Weighted Absolute Percentage Error (WAPE)\n",
    "def wape(y_verd, y_pred, eps=1e-8):\n",
    "    return np.sum(np.abs(y_pred - y_verd)) / max(np.sum(np.abs(y_verd)), eps) * 100.0\n",
    "\n",
    "# Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_verd, y_pred):\n",
    "    yt = np.log1p(np.maximum(y_verd, 0))\n",
    "    yp = np.log1p(np.maximum(y_pred, 0))\n",
    "    return np.sqrt(np.mean((yp - yt)**2))\n",
    "\n",
    "# R-squared (R2) Score\n",
    "def r2_score(y_verd, y_pred):\n",
    "    var = np.var(y_verd)\n",
    "    if var <= 0:\n",
    "        return np.nan\n",
    "    return 1.0 - np.sum((y_pred - y_verd)**2) / np.sum((y_verd - np.mean(y_verd))**2)\n",
    "\n",
    "# Función para calcular todas las métricas anteriores\n",
    "def metricas (y_verd, y_pred, eps_mape=1.0, prefix=\"\"):\n",
    "    return {\n",
    "        f\"{prefix}R2\": r2_score(y_verd, y_pred),\n",
    "        f\"{prefix}RMSLE\": rmsle(y_verd, y_pred),\n",
    "        f\"{prefix}RMSE\": rmse(y_verd, y_pred),\n",
    "        f\"{prefix}MAE\": mae(y_verd, y_pred),\n",
    "        f\"{prefix}MAPE_safe(%)\": mape_safe(y_verd, y_pred, eps=eps_mape),\n",
    "        f\"{prefix}SMAPE(%)\": smape(y_verd, y_pred),\n",
    "        f\"{prefix}WAPE(%)\": wape(y_verd, y_pred),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "50644995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 10) Valores constantes de los hiperparmámetros ===\n",
    "\n",
    "CPS = 0.5         # changepoint_prior_scale\n",
    "SPS= 10   # seasonality_prior_scale constante en el modelo final         \n",
    "YEARLY_ORDER=10 # Fourier para anual\n",
    "REGRESSOR_PRIOR = 3 # prior scale constante para regresores exógenos en el modelo final        \n",
    "PRIORS_BASE = {\"Precipitación\":10, \"Agosto\":10, \"Sol\":10, \"Tendencia\":10} # Priors base para cada variable exógena\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "131d5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 11) División del DataFrame final en conjuntos de entrenamiento y prueba ===\n",
    "\n",
    "df_full = df_prophet.copy() # DataFrame completo para modelar\n",
    "\n",
    "split = int(len(df_full) * 0.80) # Índice de división\n",
    "train = df_full.iloc[:split].copy() # Conjunto de entrenamiento\n",
    "test  = df_full.iloc[split:].copy() # Conjunto de prueba\n",
    "# print(f\"\\nTamaño train: {len(train)}, tamaño test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a0d39f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:55:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:55:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x24c696a6c90>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 12) Definición y ajuste del modelo Prophet con variables exógenas y familias relacionadas ===\n",
    "\n",
    "# Definir y ajustar el modelo Prophet con variables exógenas y familias relacionadas\n",
    "m = Prophet(\n",
    "       \n",
    "        seasonality_mode='additive', # Tipo de estacionalidad\n",
    "        changepoint_prior_scale=CPS, # Escala de prior para puntos de cambio\n",
    "        seasonality_prior_scale=SPS, # Escala de prior para estacionalidad\n",
    "        interval_width=0.95 # Intervalo de confianza del 95%\n",
    "\n",
    "    )\n",
    "\n",
    "m.add_seasonality(name='anual', period=365.25, fourier_order=YEARLY_ORDER) # Añadir estacionalidad anual con Fourier\n",
    "\n",
    "# Bucle para añadir regresores exógenos al modelo\n",
    "for c in cols_exog:\n",
    "    # Condicional para añadir solo si la columna existe en el DataFrame\n",
    "    if c in df_prophet.columns:\n",
    "        m.add_regressor(c, prior_scale=PRIORS_BASE.get(c, 0.8), standardize=True)\n",
    "\n",
    "# Bucle para añadir regresores de familias relacionadas con lag\n",
    "for fam_rel in familias_rel:\n",
    "    col_name = f\"{fam_rel}_lag{LAG_FAM}\"\n",
    "    # Condicional para añadir solo si la columna existe en el DataFrame\n",
    "    if col_name in df_prophet.columns:\n",
    "        m.add_regressor(col_name)\n",
    "\n",
    "m.fit(train) # Ajustar el modelo con el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7c721a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 13) Realizar predicciones y preparar DataFrame de resultados ===\n",
    "\n",
    "future = df_prophet[[\"ds\"] + cols_exog + [c for c in df_prophet.columns if c.endswith(f\"_lag{LAG_FAM}\")]].copy() # DataFrame futuro para predicciones\n",
    "\n",
    "forecast = m.predict(future) # Realizar predicciones\n",
    "\n",
    "forecast[\"yhat_real\"]        = np.expm1(forecast[\"yhat\"]) # Convertir predicciones logarítmicas a escala real\n",
    "forecast[\"yhat_lower_real\"]  = np.expm1(forecast[\"yhat_lower\"]) # Convertir límite inferior a escala real\n",
    "forecast[\"yhat_upper_real\"]  = np.expm1(forecast[\"yhat_upper\"]) # Convertir límite superior a escala real\n",
    "\n",
    "# Creamos el DataFrame final de forecast alineado con df_prophet\n",
    "df_forecast = df_prophet[[\"ds\", \"y\"]].merge(\n",
    "    forecast[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\", \"yhat_real\", \"yhat_lower_real\", \"yhat_upper_real\"]],\n",
    "    on=\"ds\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_forecast = df_forecast.set_index(\"ds\").sort_index() # Establecer 'ds' como índice y ordenar\n",
    "df_forecast[\"y_real\"] = np.expm1(df_forecast[\"y\"])\n",
    "\n",
    "df_forecast_train = df_forecast.iloc[:split].copy() # Conjunto de forecast para entrenamiento\n",
    "df_forecast_test = df_forecast.iloc[split:].copy() # Conjunto de forecast para prueba\n",
    "\n",
    "# print(\"\\nForecast Prophet (primeras filas):\")\n",
    "# display(df_forecast.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1f71eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet_R2: 0.01\n",
      "Prophet_RMSLE: 0.62\n",
      "Prophet_RMSE: 2,585.90\n",
      "Prophet_MAE: 2,087.54\n",
      "Prophet_MAPE_safe(%): 46.89%\n",
      "Prophet_SMAPE(%): 48.42%\n",
      "Prophet_WAPE(%): 39.75%\n"
     ]
    }
   ],
   "source": [
    "# === 14) Cálculo y visualización de métricas de evaluación del modelo ===\n",
    "\n",
    "# Calcular métricas de evaluación para el conjunto de prueba\n",
    "metrics = metricas(\n",
    "    y_verd=df_forecast_test[\"y_real\"],       \n",
    "    y_pred=df_forecast_test[\"yhat_real\"],  \n",
    "    prefix=\"Prophet_\"\n",
    ")\n",
    "\n",
    "# Visualizar las métricas calculadas\n",
    "for k, v in metrics.items():\n",
    "    suf = \"%\" if any(x in k for x in [\"WAPE\",\"SMAPE\",\"MAPE\"]) else \"\"\n",
    "    print(f\"{k}: {v:,.2f}{suf}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
